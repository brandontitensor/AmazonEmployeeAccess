
R version 4.3.1 (2023-06-16) -- "Beagle Scouts"
Copyright (C) 2023 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #############
> ##LIBRARIES##
> #############
> 
> library(tidymodels) 
── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──
✔ broom        1.0.5     ✔ recipes      1.0.8
✔ dials        1.2.0     ✔ rsample      1.2.0
✔ dplyr        1.1.3     ✔ tibble       3.2.1
✔ ggplot2      3.4.3     ✔ tidyr        1.3.0
✔ infer        1.0.5     ✔ tune         1.1.2
✔ modeldata    1.2.0     ✔ workflows    1.1.3
✔ parsnip      1.1.1     ✔ workflowsets 1.0.1
✔ purrr        1.0.2     ✔ yardstick    1.2.0
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Use suppressPackageStartupMessages() to eliminate package startup messages
> library(tidyverse)
── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ forcats   1.0.0     ✔ readr     2.1.4
✔ lubridate 1.9.3     ✔ stringr   1.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ readr::col_factor() masks scales::col_factor()
✖ purrr::discard()    masks scales::discard()
✖ dplyr::filter()     masks stats::filter()
✖ stringr::fixed()    masks recipes::fixed()
✖ dplyr::lag()        masks stats::lag()
✖ readr::spec()       masks yardstick::spec()
ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
> library(vroom) 

Attaching package: ‘vroom’

The following objects are masked from ‘package:readr’:

    as.col_spec, col_character, col_date, col_datetime, col_double,
    col_factor, col_guess, col_integer, col_logical, col_number,
    col_skip, col_time, cols, cols_condense, cols_only, date_names,
    date_names_lang, date_names_langs, default_locale, fwf_cols,
    fwf_empty, fwf_positions, fwf_widths, locale, output_column,
    problems, spec

The following object is masked from ‘package:yardstick’:

    spec

The following object is masked from ‘package:scales’:

    col_factor

> library(glmnet)
Loading required package: Matrix

Attaching package: ‘Matrix’

The following objects are masked from ‘package:tidyr’:

    expand, pack, unpack

Loaded glmnet 4.1-8
> library(randomForest)
randomForest 4.7-1.1
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:ggplot2’:

    margin

The following object is masked from ‘package:dplyr’:

    combine

> library(doParallel)
Loading required package: foreach

Attaching package: ‘foreach’

The following objects are masked from ‘package:purrr’:

    accumulate, when

Loading required package: iterators
Loading required package: parallel
> library(xgboost)

Attaching package: ‘xgboost’

The following object is masked from ‘package:dplyr’:

    slice

> tidymodels_prefer()
> conflicted::conflicts_prefer(yardstick::rmse)
[conflicted] Will prefer yardstick::rmse over any other package.
> library(rpart)
> library(stacks)
> library(embed)
> library(discrim)
> library(naivebayes)
naivebayes 0.9.7 loaded
> library(kknn)
> library(themis)
> 
> 
> ####################
> ##WORK IN PARALLEL##
> ####################
> 
> #all_cores <- parallel::detectCores(logical = FALSE)
> #num_cores <- makePSOCKcluster(NUMBER OF CORES)
> #registerDoParallel(cores = all_cores)
> 
> #stopCluster(num_cores)
> 
> ########
> ##DATA##
> ########
> 
> my_data <- vroom("train.csv")
Rows: 32769 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): ACTION, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTN...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> test_data <- vroom("test.csv")
Rows: 58921 Columns: 10
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl (10): id, RESOURCE, MGR_ID, ROLE_ROLLUP_1, ROLE_ROLLUP_2, ROLE_DEPTNAME,...

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
> my_data$ACTION <- as.factor(my_data$ACTION)
> 
> #######
> ##EDA##
> #######
> 
> #DataExplorer::plot_histogram(my_data)
> #GGally::ggpairs(my_data)
> 
> #plot_1 <- ggplot(data=my_data) +
> #  geom_mosaic(aes(x=product(RESOURCE), fill = ACTION))
> 
> ##########
> ##RECIPE##
> ##########
> 
> my_recipe <- recipe(ACTION~., data=my_data) %>%
+ step_mutate_at(all_numeric_predictors(), fn = factor) %>% # turn all numeric features into factors5
+  # combines categorical values that occur <5% into an "other" value6
+   #step_dummy(all_nominal_predictors()) %>% 
+   step_lencode_mixed(all_nominal_predictors(), outcome = vars(ACTION)) %>% 
+   step_normalize(all_numeric_predictors()) %>% 
+   step_pca(all_predictors(), threshold = .95) %>% 
+   step_smote(all_outcomes(), neighbors=7)
> 
> 
> prepped_recipe <- prep(my_recipe, verbose = T)
oper 1 step mutate at [training] 
oper 2 step lencode mixed [training] 
oper 3 step normalize [training] 
oper 4 step pca [training] 
oper 5 step smote [training] 
The retained training set is ~ 3.54 Mb  in memory.

> bake_1 <- bake(prepped_recipe, new_data = NULL)
> 
> 
> #######################
> ##LOGISTIC REGRESSION##
> #######################
> 
> my_data$ACTION <- as.factor(my_data$ACTION)
> 
> logistic_mod <- logistic_reg() %>% 
+   set_engine("glm")
> 
> logistic_workflow <- workflow() %>%
+ add_recipe(my_recipe) %>%
+ add_model(logistic_mod) %>%
+ fit(data = my_data)
> 
> extract_fit_engine(logistic_workflow) %>% #Extracts model details from workflow
+   summary()

Call:
stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept)  4.99726    0.05911  84.547   <2e-16 ***
PC1         -1.12414    0.01401 -80.217   <2e-16 ***
PC2         -0.49019    0.01664 -29.464   <2e-16 ***
PC3          2.82449    0.03231  87.415   <2e-16 ***
PC4          0.62482    0.02073  30.144   <2e-16 ***
PC5         -1.31796    0.03285 -40.117   <2e-16 ***
PC6         -1.26337    0.03531 -35.778   <2e-16 ***
PC7          0.02395    0.03594   0.666    0.505    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 85595  on 61743  degrees of freedom
Residual deviance: 17836  on 61736  degrees of freedom
AIC: 17852

Number of Fisher Scoring iterations: 8

> 
> logistic_predictions <- predict(logistic_workflow,
+                               new_data=test_data,
+                               type= "prob")
> logistic_predictions <- cbind(test_data$id,logistic_predictions$.pred_1)
> 
> colnames(logistic_predictions) <- c("id","ACTION")
> summary(logistic_predictions)
       id            ACTION         
 Min.   :    1   Min.   :0.0000026  
 1st Qu.:14731   1st Qu.:0.9438727  
 Median :29461   Median :0.9969210  
 Mean   :29461   Mean   :0.8799822  
 3rd Qu.:44191   3rd Qu.:0.9995763  
 Max.   :58921   Max.   :0.9999999  
> 
> logistic_predictions <- as.data.frame(logistic_predictions)
> 
> vroom_write(logistic_predictions,"logistic_predictions_smote.csv",',')
> 
> #######################
> ##PENALIZED LOGISTIC##
> ######################
> 
> plog_mod <- logistic_reg(mixture = tune(),
+                          penalty = tune()) %>% 
+   set_engine("glmnet")
> 
> plog_workflow <- workflow() %>%
+   add_recipe(my_recipe) %>%
+   add_model(plog_mod)
> 
> tuning_grid <- grid_regular(penalty(),
+                            mixture(),
+                            levels = 5) ## L^2 total tuning possibilities13
> 
> ## Split data for CV
> folds <- vfold_cv(my_data, v = 3, repeats=1)
> 
> 
> CV_results <- plog_workflow %>%
+ tune_grid(resamples=folds,
+           grid=tuning_grid,
+           metrics=metric_set(roc_auc, f_meas, sens, recall, spec,
+                              precision, accuracy)) 
→ A | warning: While computing binary `precision()`, no predicted events were detected (i.e. `true_positive + false_positive = 0`). 
               Precision is undefined in this case, and `NA` will be returned.
               Note that 625 true event(s) actually occured for the problematic event level, '0'.
There were issues with some computations   A: x1
There were issues with some computations   A: x1

> bestTune <- CV_results %>%
+ select_best("roc_auc")
> 
> final_plog_workflow <-
+ plog_workflow %>%
+ finalize_workflow(bestTune) %>%
+ fit(data=my_data)
> 
> ## Predict
> plog_predictions <- final_plog_workflow %>%
+ predict(new_data = test_data, type="prob")
> 
> plog_predictions <- cbind(test_data$id,plog_predictions$.pred_1)
> 
> colnames(plog_predictions) <- c("id","ACTION")
> 
> 
> plog_predictions <- as.data.frame(plog_predictions)
> 
> vroom_write(plog_predictions,"plog_predictions_smote.csv",',')
> 
> #################################
> ##RANDOM FOREST CLASSIFICATIONS##
> #################################
> 
> RF_model <- rand_forest(mode = "classification",
+                         mtry = tune(),
+                         trees = 750,
+                         min_n = tune()) %>% #Applies Linear Model
+   set_engine("ranger")
> 
> RF_workflow <- workflow() %>% #Creates a workflow
+   add_recipe(my_recipe) %>% #Adds in my recipe
+   add_model(RF_model) 
> 
> tuning_grid_rf <- grid_regular(mtry(range = c(1,10)),
+                                min_n(),
+                                levels = 10)
> folds_rf <- vfold_cv(my_data, v = 20, repeats=1)
> 
> CV_results_rf <- RF_workflow %>%
+   tune_grid(resamples=folds_rf,
+             grid=tuning_grid_rf,
+             metrics=metric_set(roc_auc, f_meas, sens, recall, spec,
+                                precision, accuracy))
→ A | warning: Model failed to converge with max|grad| = 0.354744 (tol = 0.002, component 1), Model is nearly unidentifiable: very large eigenvalue
                - Rescale variables?
There were issues with some computations   A: x1
→ B | warning: 8 columns were requested but there were 7 predictors in the data. 7 will be used.
There were issues with some computations   A: x1There were issues with some computations   A: x1   B: x1
→ C | warning: 9 columns were requested but there were 7 predictors in the data. 7 will be used.
There were issues with some computations   A: x1   B: x1There were issues with some computations   A: x1   B: x1   C: x1
→ D | warning: 10 columns were requested but there were 7 predictors in the data. 7 will be used.
There were issues with some computations   A: x1   B: x1   C: x1There were issues with some computations   A: x1   B: x1   C: x1   D: x1
There were issues with some computations   A: x1   B: x2   C: x1   D: x1
There were issues with some computations   A: x1   B: x2   C: x2   D: x1
There were issues with some computations   A: x1   B: x2   C: x2   D: x2
There were issues with some computations   A: x1   B: x3   C: x2   D: x2
There were issues with some computations   A: x1   B: x3   C: x3   D: x2
There were issues with some computations   A: x1   B: x3   C: x3   D: x3
